{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the first step which generates the data from the datacube.   \n",
    "We were provided of the linescan id numbers by which we can get the linescan images.   \n",
    "When the linescan image data is retrieved, we find the minimum and maximum of the longitude and the latitude, and find the median color values between 2017 and 2019 from the same coordinate.   \n",
    "After finding the median, we will add two variables; the NDVI and the MNDWI index.\n",
    "\n",
    "When everything is ready, we also engineered 25 different masks using a different combination of maskOpen and maskClose parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datacube import Datacube\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../scripts\")\n",
    "from datacube.utils.cog import write_cog\n",
    "from dea_bandindices import calculate_indices\n",
    "from dea_datahandling import load_ard\n",
    "from dea_dask import create_local_dask_cluster\n",
    "from mpl_toolkits.mplot3d import Axes3D #to plot in 3D\n",
    "import matplotlib.pyplot as plt         #to plot arrays as images\n",
    "from matplotlib import colors           #extra colour representations\n",
    "from matplotlib import cm               #extra colour representations\n",
    "import numpy as np                      #to manipulate arrays\n",
    "import cv2                              #to perform more complex manipulations on arrays\n",
    "import geopandas as gpd\n",
    "\n",
    "from dea_plotting import map_shapefile\n",
    "from dea_spatialtools import xr_rasterize\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37821</li>\n",
       "  <li><b>Dashboard: </b><a href='/proxy/8787/status' target='_blank'>/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>8.95 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37821' processes=1 threads=6, memory=8.95 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/drivers/postgres/_connections.py:87: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    }
   ],
   "source": [
    "create_local_dask_cluster()\n",
    "dc = Datacube(app = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linescan_datasets = dc.find_datasets(product='linescan')\n",
    "linescan_datasets = sorted(linescan_datasets, key = lambda ds: (ds.center_time, ds.id))\n",
    "linescan_datasets = pd.Series(linescan_datasets)\n",
    "indices = pd.read_csv('../03_EY_challenge1/trainindices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DD</th>\n",
       "      <th>gdf</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABERFELDY_WEST_200_P1_201901260955_MGA94_55</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ABERFELDY_WEST_214_P1_201901261750_MGA94_55</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CREAM_JIM_JORDAN_217_P1_201901262218_MGA94_55</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>JORDAN_231_P1_201901271500_MGA94_55</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>JORDAN_234_P1_201901271901_MGA94_55</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   DD                                            gdf  train\n",
       "0  I1  0.0    ABERFELDY_WEST_200_P1_201901260955_MGA94_55     23\n",
       "1  I2  1.0    ABERFELDY_WEST_214_P1_201901261750_MGA94_55     26\n",
       "2  I3  2.0  CREAM_JIM_JORDAN_217_P1_201901262218_MGA94_55     27\n",
       "3  I4  5.0            JORDAN_231_P1_201901271500_MGA94_55     29\n",
       "4  I5  6.0            JORDAN_234_P1_201901271901_MGA94_55     31"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file = '../03_EY_challenge1/resources/fire_boundaries.shp'\n",
    "gdf = gpd.read_file(vector_file)\n",
    "def clean_name(name):\n",
    "    if name is None:\n",
    "        res = None\n",
    "    else:\n",
    "        if name.upper()[-4::] == \".JPG\":\n",
    "            res = name.upper()[:-4].replace(' ','_')\n",
    "        else:\n",
    "            res = name.upper().replace(' ','_')\n",
    "    return res\n",
    "gdf['SourceNameClean'] = gdf.apply(lambda row: clean_name(row.SourceName), axis=1)\n",
    "gdf.dtUTC = gdf.apply(lambda row: datetime.strptime(row.dtUTC, '%Y-%m-%d %H:%M:%S'), axis=1)\n",
    "gdf.dtLocal = gdf.apply(lambda row: datetime.strptime(row.dtLocal, '%Y-%m-%d %H:%M:%S'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_array = np.array([1,3,5,7,9])\n",
    "close_array = np.array([25,36, 49, 64,81]) \n",
    "comb = []\n",
    "for o in open_array:\n",
    "    for c in close_array:\n",
    "        comb.append((int(o),int(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throught the for-loop process below, we will retrieve the linescan image data and aquire their coordinate information. Using the cooridnate information, we will obtain median of NBART colors (blue, green, red, nir, swir_2, swir_1), and will also compute the NDVI and MNDWI.   \n",
    "\n",
    "Finally, we first select the pixels whose linesan values are greater than 100. Then, we will engineer 25 different masks using the combination of the parameters for the maskOpen and maskClose method. When they are generated, having the value 255 means they are inside the given mask and having 0 means they are outside of the mask. The initial assumption was that these binary variables would be useful for the tree-based models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the combination of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (1, 25)\n",
       "1     (1, 36)\n",
       "2     (1, 49)\n",
       "3     (1, 64)\n",
       "4     (1, 81)\n",
       "5     (3, 25)\n",
       "6     (3, 36)\n",
       "7     (3, 49)\n",
       "8     (3, 64)\n",
       "9     (3, 81)\n",
       "10    (5, 25)\n",
       "11    (5, 36)\n",
       "12    (5, 49)\n",
       "13    (5, 64)\n",
       "14    (5, 81)\n",
       "15    (7, 25)\n",
       "16    (7, 36)\n",
       "17    (7, 49)\n",
       "18    (7, 64)\n",
       "19    (7, 81)\n",
       "20    (9, 25)\n",
       "21    (9, 36)\n",
       "22    (9, 49)\n",
       "23    (9, 64)\n",
       "24    (9, 81)\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the for-loop process explained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, gdf_name in zip(indices.train, indices.gdf):\n",
    "    dc = Datacube(app = \"\")\n",
    "    src = dc.load(product='linescan', id=linescan_datasets[index].id, output_crs='epsg:28355', resolution=(-10,10))\n",
    "    ob = gdf.loc[gdf.SourceNameClean == gdf_name]\n",
    "    src['tgt'] = xr_rasterize(gdf=ob, da=src)\n",
    "    src = src.isel(time = 0)\n",
    "    crs = src.crs\n",
    "    x_min, x_max, y_min, y_max = int(src.x.min().values), int(src.x.max().values), int(src.y.min().values), int(src.y.max().values)\n",
    "    lon_range = (x_min, x_max)\n",
    "    lat_range = (y_min, y_max)\n",
    "    resolution = (-10, 10)\n",
    "\n",
    "    query = {\n",
    "        'x': lon_range,\n",
    "        'y': lat_range,\n",
    "        'time': ('2017','2019'),\n",
    "        'measurements': [\n",
    "            'nbart_blue', 'nbart_green', 'nbart_red', 'nbart_nir', 'nbart_swir_2',\n",
    "            'nbart_swir_1'\n",
    "        ],\n",
    "        'crs' : crs,\n",
    "        'output_crs': crs,\n",
    "        'resolution': (-10, 10),\n",
    "        'group_by': 'solar_day',\n",
    "    }\n",
    "    history = load_ard(dc=dc, products=['ga_ls8c_ard_3','ga_ls7e_ard_3'], \n",
    "                              dask_chunks={'time': 1}, min_gooddata=0.85, ls7_slc_off=True, **query) \n",
    "    history = calculate_indices(history, index=['NDVI','MNDWI'], collection='ga_ls_3').median('time') \n",
    "    src = src.merge(history)\n",
    "    del history\n",
    "\n",
    "    lowerBound=100\n",
    "    upperBound=255\n",
    "\n",
    "    #create the mask over the top of our original image\n",
    "    linescan_mask = cv2.inRange(src.linescan.values,lowerBound,upperBound)\n",
    "\n",
    "    for i, (o, c) in enumerate(comb):\n",
    "\n",
    "        #establish dialation and contraction parameters\n",
    "        kernelOpen=np.ones((o,o)) # try it yourself!\n",
    "        kernelClose=np.ones((c,c))    \n",
    "\n",
    "        #denoise the pixels\n",
    "        maskOpen=cv2.morphologyEx(linescan_mask,cv2.MORPH_OPEN,kernelOpen)\n",
    "\n",
    "        maskClose=cv2.morphologyEx(maskOpen,cv2.MORPH_CLOSE,kernelClose)\n",
    "\n",
    "        src[f'maskOpen_{i}'] = (['y','x'], maskOpen)\n",
    "        src[f'maskClose_{i}'] = (['y','x'], maskClose)\n",
    "        \n",
    "        del maskOpen\n",
    "        del maskClose\n",
    "    df = src.to_dataframe()\n",
    "    del src\n",
    "    del dc\n",
    "    df = df.reset_index().drop(['time', 'spatial_ref'], axis = 1)\n",
    "    tgt = df.tgt\n",
    "    df.drop('tgt', axis = 1, inplace = True)\n",
    "    df['tgt'] = tgt\n",
    "    del tgt\n",
    "    df.to_csv(f'./Datasets/train_{index}.csv', index = False)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the same process for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../03_EY_challenge1/test.csv')\n",
    "fname = test.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['JORDAN_235_P1_201901281204_MGA94_55',\n",
       "       'JORDAN_294_P1_201902011150_MGA94_55',\n",
       "       'WALHALLA_313_P1_201902020733_MGA94_55',\n",
       "       'WALHALLA_353_P1_201902031625_MGA94_55',\n",
       "       'MACALISTER91_648_P1_201903070444_MGA94_55'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j, f in enumerate(fname):\n",
    "    dc = Datacube(app = \"\")\n",
    "    src = dc.load(product='linescan', label=f, output_crs='epsg:28355', resolution=(-10,10))\n",
    "    src = src.isel(time = 0)\n",
    "    crs = src.crs\n",
    "    x_min, x_max, y_min, y_max = int(src.x.min().values), int(src.x.max().values), int(src.y.min().values), int(src.y.max().values)\n",
    "    lon_range = (x_min, x_max)\n",
    "    lat_range = (y_min, y_max)\n",
    "    resolution = (-10, 10)\n",
    "\n",
    "    query = {\n",
    "        'x': lon_range,\n",
    "        'y': lat_range,\n",
    "        'time': ('2017','2019'),\n",
    "        'measurements': [\n",
    "            'nbart_blue', 'nbart_green', 'nbart_red', 'nbart_nir', 'nbart_swir_2',\n",
    "            'nbart_swir_1'\n",
    "        ],\n",
    "        'crs' : crs,\n",
    "        'output_crs': crs,\n",
    "        'resolution': (-10, 10),\n",
    "        'group_by': 'solar_day',\n",
    "    }\n",
    "    history = load_ard(dc=dc, products=['ga_ls8c_ard_3','ga_ls7e_ard_3'], \n",
    "                              dask_chunks={'time': 1}, min_gooddata=0.85, ls7_slc_off=True, **query) \n",
    "    history = calculate_indices(history, index=['NDVI','MNDWI'], collection='ga_ls_3').median('time') \n",
    "    src = src.merge(history)\n",
    "    del history\n",
    "    lowerBound=80\n",
    "    upperBound=255\n",
    "\n",
    "    #create the mask over the top of our original image\n",
    "    linescan_mask = cv2.inRange(src.linescan.values,lowerBound,upperBound)\n",
    "\n",
    "    for i, (o, c) in enumerate(comb):\n",
    "\n",
    "        #establish dialation and contraction parameters\n",
    "        kernelOpen=np.ones((o,o)) # try it yourself!\n",
    "        kernelClose=np.ones((c,c))    \n",
    "\n",
    "        #denoise the pixels\n",
    "        maskOpen=cv2.morphologyEx(linescan_mask,cv2.MORPH_OPEN,kernelOpen)\n",
    "\n",
    "        maskClose=cv2.morphologyEx(maskOpen,cv2.MORPH_CLOSE,kernelClose)\n",
    "\n",
    "        src[f'maskOpen_{i}'] = (['y','x'], maskOpen)\n",
    "        src[f'maskClose_{i}'] = (['y','x'], maskClose)\n",
    "\n",
    "        del maskOpen\n",
    "        del maskClose\n",
    "    df = src.to_dataframe()\n",
    "    del src\n",
    "    df.reset_index(inplace = True)\n",
    "    df.drop(['time','spatial_ref'], axis = 1, inplace = True)\n",
    "    df[['x','y']] = df[['x','y']].astype(int)\n",
    "    df.to_csv(f'test_{j+2}.csv', index = False)\n",
    "    del df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
